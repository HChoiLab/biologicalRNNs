{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea68d78-d5dc-4855-8a97-95d273306208",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8eaf15-6515-45bd-b403-b5d421433fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010b8d7-47e4-4cfd-92de-046523367c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eig, svd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import levene, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca1fc0-1549-4120-be34-64fc3716d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b16214-4820-4e8b-8e6b-192c234a81c9",
   "metadata": {},
   "source": [
    "#### Load paths\n",
    "Make edits as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8930501-19e3-4f92-a0b7-c44002371324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Aish_celltypeRNN/Dales-backprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49b826-c84a-460c-b257-73874ee3b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import makeTensorLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9679025-c509-44f5-a8c4-9c4b39518634",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc66bc1-6074-4cf9-8930-2fb30e78ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print('GPU found, training on GPU')\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74178279-3b75-42aa-b25f-2c51bf04af8a",
   "metadata": {},
   "source": [
    "#### Model related hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb747cee-6c35-490b-9809-a128f455b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nRuns = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e3a52-a4a7-4003-8da4-5b384f126d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200 ##100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69480498-785a-4d68-befa-33ad15e90a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_scaling = 16\n",
    "pop_list_types = [12,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88244d-c464-4eee-9be4-6cdea72f6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_areas = 2\n",
    "n_depths = 3\n",
    "\n",
    "## Number of recurrent neurons in total\n",
    "N = int(n_areas*n_depths*np.sum(pop_list_types)*latent_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f613182-cf09-4d6f-840b-a97f53e11d2e",
   "metadata": {},
   "source": [
    "#### Data loading for runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd50bd-3c08-42c9-9cea-a39c91775f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = '/content/drive/MyDrive/Aish_celltypeRNN/data-processing/averaged_familiar_change/train_test/'\n",
    "\n",
    "suffix = 'familiar_omission'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ac3cc-7073-4511-92bd-e2ed26331217",
   "metadata": {},
   "source": [
    "#### Note on nomenclature!\n",
    "Train is input data and test is output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509071b8-3d77-4326-a36b-562adbb27e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fitting data\n",
    "dff_V1_L4_sst_train = np.load(default_path + 'dff_V1_L4_sst_' + suffix + '_train.npy')\n",
    "dff_V1_L23_sst_train = np.load(default_path +'dff_V1_L23_sst_' + suffix + '_train.npy')\n",
    "dff_V1_L5_sst_train = np.load(default_path +'dff_V1_L5_sst_' + suffix + '_train.npy')\n",
    "\n",
    "dff_V1_L4_vip_train = np.load(default_path +'dff_V1_L4_vip_' + suffix + '_train.npy')\n",
    "dff_V1_L23_vip_train = np.load(default_path +'dff_V1_L23_vip_' + suffix + '_train.npy')\n",
    "dff_V1_L5_vip_train = np.load(default_path +'dff_V1_L5_vip_' + suffix + '_train.npy')\n",
    "\n",
    "dff_V1_L4_pyr_train = np.load(default_path +'dff_V1_L4_pyr_' + suffix + '_train.npy')\n",
    "dff_V1_L23_pyr_train = np.load(default_path +'dff_V1_L23_pyr_' + suffix + '_train.npy')\n",
    "dff_V1_L5_pyr_train = np.load(default_path +'dff_V1_L5_pyr_' + suffix + '_train.npy')\n",
    "\n",
    "dff_LM_L4_sst_train = np.load(default_path +'dff_LM_L4_sst_' + suffix + '_train.npy')\n",
    "dff_LM_L23_sst_train = np.load(default_path +'dff_LM_L23_sst_' + suffix + '_train.npy')\n",
    "dff_LM_L5_sst_train = np.load(default_path +'dff_LM_L5_sst_' + suffix + '_train.npy')\n",
    "\n",
    "dff_LM_L4_vip_train = np.load(default_path +'dff_LM_L4_vip_' + suffix + '_train.npy')\n",
    "dff_LM_L23_vip_train = np.load(default_path +'dff_LM_L23_vip_' + suffix + '_train.npy')\n",
    "dff_LM_L5_vip_train = np.load(default_path +'dff_LM_L5_vip_' + suffix + '_train.npy')\n",
    "\n",
    "dff_LM_L4_pyr_train = np.load(default_path +'dff_LM_L4_pyr_' + suffix + '_train.npy')\n",
    "dff_LM_L23_pyr_train = np.load(default_path +'dff_LM_L23_pyr_' + suffix + '_train.npy')\n",
    "dff_LM_L5_pyr_train = np.load(default_path +'dff_LM_L5_pyr_' + suffix + '_train.npy')\n",
    "\n",
    "# Loading predictive data\n",
    "dff_V1_L4_pyr_test = np.load(default_path +'dff_V1_L4_pyr_' + suffix + '_test.npy')\n",
    "dff_V1_L23_pyr_test = np.load(default_path +'dff_V1_L23_pyr_' + suffix + '_test.npy')\n",
    "dff_V1_L5_pyr_test = np.load(default_path +'dff_V1_L5_pyr_' + suffix + '_test.npy')\n",
    "\n",
    "dff_V1_L4_sst_test = np.load(default_path +'dff_V1_L4_sst_' + suffix + '_test.npy')\n",
    "dff_V1_L23_sst_test = np.load(default_path +'dff_V1_L23_sst_' + suffix + '_test.npy')\n",
    "dff_V1_L5_sst_test = np.load(default_path +'dff_V1_L5_sst_' + suffix + '_test.npy')\n",
    "\n",
    "dff_V1_L4_vip_test = np.load(default_path +'dff_V1_L4_vip_' + suffix + '_test.npy')\n",
    "dff_V1_L23_vip_test = np.load(default_path +'dff_V1_L23_vip_' + suffix + '_test.npy')\n",
    "dff_V1_L5_vip_test = np.load(default_path +'dff_V1_L5_vip_' + suffix + '_test.npy')\n",
    "\n",
    "dff_LM_L4_pyr_test = np.load(default_path +'dff_LM_L4_pyr_' + suffix + '_test.npy')\n",
    "dff_LM_L23_pyr_test = np.load(default_path +'dff_LM_L23_pyr_' + suffix + '_test.npy')\n",
    "dff_LM_L5_pyr_test = np.load(default_path +'dff_LM_L5_pyr_' + suffix + '_test.npy')\n",
    "\n",
    "dff_LM_L4_sst_test = np.load(default_path +'dff_LM_L4_sst_' + suffix + '_test.npy')\n",
    "dff_LM_L23_sst_test = np.load(default_path +'dff_LM_L23_sst_' + suffix + '_test.npy')\n",
    "dff_LM_L5_sst_test = np.load(default_path +'dff_LM_L5_sst_' + suffix + '_test.npy')\n",
    "\n",
    "dff_LM_L4_vip_test = np.load(default_path +'dff_LM_L4_vip_' + suffix + '_test.npy')\n",
    "dff_LM_L23_vip_test = np.load(default_path +'dff_LM_L23_vip_' + suffix + '_test.npy')\n",
    "dff_LM_L5_vip_test = np.load(default_path +'dff_LM_L5_vip_' + suffix + '_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d48d2-986a-486a-96fa-081ba9bd4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train_set = np.dstack((dff_V1_L4_pyr_train, dff_V1_L4_sst_train, dff_V1_L4_vip_train,\n",
    "                               dff_V1_L23_pyr_train, dff_V1_L23_sst_train, dff_V1_L23_vip_train,\n",
    "                               dff_V1_L5_pyr_train, dff_V1_L5_sst_train, dff_V1_L5_vip_train,\n",
    "                               dff_LM_L4_pyr_train, dff_LM_L4_sst_train, dff_LM_L4_vip_train,\n",
    "                               dff_LM_L23_pyr_train, dff_LM_L23_sst_train, dff_LM_L23_vip_train,\n",
    "                               dff_LM_L5_pyr_train, dff_LM_L5_sst_train, dff_LM_L5_vip_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df2c72-8ab4-4a80-9ad9-5b1d75e72f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_test_set = np.dstack((dff_V1_L4_pyr_test, dff_V1_L4_sst_test, dff_V1_L4_vip_test,\n",
    "                               dff_V1_L23_pyr_test, dff_V1_L23_sst_test, dff_V1_L23_vip_test,\n",
    "                               dff_V1_L5_pyr_test, dff_V1_L5_sst_test, dff_V1_L5_vip_test,\n",
    "                               dff_LM_L4_pyr_test, dff_LM_L4_sst_test, dff_LM_L4_vip_test,\n",
    "                               dff_LM_L23_pyr_test, dff_LM_L23_sst_test, dff_LM_L23_vip_test,\n",
    "                               dff_LM_L5_pyr_test, dff_LM_L5_sst_test, dff_LM_L5_vip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdb600-7823-4713-9190-8e4e000b79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, idxs in enumerate(range(25,30)):\n",
    "    plt.subplot(5,1,ii+1)\n",
    "    plt.plot(dff_V1_L4_pyr_train[idxs])\n",
    "    plt.plot(dff_V1_L4_pyr_test[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0946bc2-cc60-444d-90e9-145dfb1a9ef2",
   "metadata": {},
   "source": [
    "#### Directory init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698a135-f21d-43d0-82e9-b61fb5be6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = '/content/drive/My Drive/Aish_celltypeRNN/Repeated-Runs-Dales-Pruning/Familiar-Change-Sparse-Frozen/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95666bfd-32e3-4fcf-9d61-b6cef9c064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "npp = {}\n",
    "pp_npy = {}\n",
    "pp_pts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4cbd2-d112-4970-b7a1-a4956f463416",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "\n",
    "    npp[cntr] = 'celltype-dale-pruning-latent-16-'+str(cntr)+'/'\n",
    "    pp_npy[cntr] = pp+npp[cntr]+'npys-'+str(cntr)+'/'\n",
    "    pp_pts[cntr] = pp+npp[cntr]+'pts-'+str(cntr)+'/'\n",
    "\n",
    "    os.mkdir(os.path.join(pp,npp[cntr]))\n",
    "    os.mkdir(os.path.join(pp,npp[cntr],pp_npy[cntr]))\n",
    "    os.mkdir(os.path.join(pp,npp[cntr],pp_pts[cntr]))\n",
    "\n",
    "    os.mkdir(os.path.join(pp,npp[cntr],pp_npy[cntr],'Dataset/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f479104-139e-47e2-9875-4bc597dc1615",
   "metadata": {},
   "source": [
    "#### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780feec0-957b-4e00-9ec5-47d2cdc3313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.random.randint(1000, size=nRuns)\n",
    "np.save(pp_npy[cntr]+'seeds',seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1c5a6-e314-4343-89f0-9849fc2e2461",
   "metadata": {},
   "source": [
    "#### Block indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5eabfb-8186-4807-95ab-c0baa905aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr = ['V1_L4_pyr','V1_L4_sst','V1_L4_vip',\n",
    "             'V1_L23_pyr','V1_L23_sst','V1_L23_vip',\n",
    "             'V1_L5_pyr','V1_L5_sst','V1_L5_vip',\n",
    "             'LM_L4_pyr','LM_L4_sst','LM_L4_vip',\n",
    "             'LM_L23_pyr','LM_L23_sst','LM_L23_vip',\n",
    "             'LM_L5_pyr','LM_L5_sst','LM_L5_vip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a332784-0530-430f-ade6-1f99c1cb036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cell_types = len(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285510a2-c848-4f2e-a6ac-689edc26e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_V1_L4_Pyr = 0\n",
    "end_V1_L4_Pyr = start_V1_L4_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_V1_L4_SST = end_V1_L4_Pyr\n",
    "end_V1_L4_SST = start_V1_L4_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_V1_L4_VIP = end_V1_L4_SST\n",
    "end_V1_L4_VIP = start_V1_L4_VIP + pop_list_types[2]*latent_scaling\n",
    "\n",
    "## V1, L2/3\n",
    "start_V1_L23_Pyr = end_V1_L4_VIP\n",
    "end_V1_L23_Pyr = start_V1_L23_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_V1_L23_SST = end_V1_L23_Pyr\n",
    "end_V1_L23_SST = start_V1_L23_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_V1_L23_VIP = end_V1_L23_SST\n",
    "end_V1_L23_VIP = start_V1_L23_VIP + pop_list_types[2]*latent_scaling\n",
    "\n",
    "## V1, L5\n",
    "start_V1_L5_Pyr = end_V1_L23_VIP\n",
    "end_V1_L5_Pyr = start_V1_L5_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_V1_L5_SST = end_V1_L5_Pyr\n",
    "end_V1_L5_SST = start_V1_L5_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_V1_L5_VIP = end_V1_L5_SST\n",
    "end_V1_L5_VIP = start_V1_L5_VIP + pop_list_types[2]*latent_scaling\n",
    "\n",
    "## LM, L4\n",
    "start_LM_L4_Pyr = end_V1_L5_VIP ## would need to be changed if using L6 populations as well\n",
    "end_LM_L4_Pyr = start_LM_L4_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_LM_L4_SST = end_LM_L4_Pyr\n",
    "end_LM_L4_SST = start_LM_L4_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_LM_L4_VIP = end_LM_L4_SST\n",
    "end_LM_L4_VIP = start_LM_L4_VIP + pop_list_types[2]*latent_scaling\n",
    "\n",
    "## LM, L2/3\n",
    "start_LM_L23_Pyr = end_LM_L4_VIP\n",
    "end_LM_L23_Pyr = start_LM_L23_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_LM_L23_SST = end_LM_L23_Pyr\n",
    "end_LM_L23_SST = start_LM_L23_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_LM_L23_VIP = end_LM_L23_SST\n",
    "end_LM_L23_VIP = start_LM_L23_VIP + pop_list_types[2]*latent_scaling\n",
    "\n",
    "## LM, L5\n",
    "start_LM_L5_Pyr = end_LM_L23_VIP\n",
    "end_LM_L5_Pyr = start_LM_L5_Pyr + pop_list_types[0]*latent_scaling\n",
    "\n",
    "start_LM_L5_SST = end_LM_L5_Pyr\n",
    "end_LM_L5_SST = start_LM_L5_SST + pop_list_types[1]*latent_scaling\n",
    "\n",
    "start_LM_L5_VIP = end_LM_L5_SST\n",
    "end_LM_L5_VIP = start_LM_L5_VIP + pop_list_types[2]*latent_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c059a8-7a28-4387-a63c-c8205885e568",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e35f0-b185-4e11-8f28-a83043ba7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class CelltypeRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, device):\n",
    "\n",
    "        super(CelltypeRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, batch_first=True, nonlinearity='tanh', bias=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc2 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc3 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "        self.fc4 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc5 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc6 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "        self.fc7 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc8 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc9 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "\n",
    "        self.fc10 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc11 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc12 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "        self.fc13 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc14 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc15 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "        self.fc16 = nn.Linear(round(pop_list_types[0]*latent_scaling), num_classes)\n",
    "        self.fc17 = nn.Linear(round(pop_list_types[1]*latent_scaling), num_classes)\n",
    "        self.fc18 = nn.Linear(round(pop_list_types[2]*latent_scaling), num_classes)\n",
    "\n",
    "        self.fc1.weight.requires_grad = False\n",
    "        self.fc1.bias.requires_grad = False\n",
    "\n",
    "        self.fc2.weight.requires_grad = False\n",
    "        self.fc2.bias.requires_grad = False\n",
    "\n",
    "        self.fc3.weight.requires_grad = False\n",
    "        self.fc3.bias.requires_grad = False\n",
    "\n",
    "        self.fc4.weight.requires_grad = False\n",
    "        self.fc4.bias.requires_grad = False\n",
    "\n",
    "        self.fc5.weight.requires_grad = False\n",
    "        self.fc5.bias.requires_grad = False\n",
    "\n",
    "        self.fc6.weight.requires_grad = False\n",
    "        self.fc6.bias.requires_grad = False\n",
    "\n",
    "        self.fc7.weight.requires_grad = False\n",
    "        self.fc7.bias.requires_grad = False\n",
    "\n",
    "        self.fc8.weight.requires_grad = False\n",
    "        self.fc8.bias.requires_grad = False\n",
    "\n",
    "        self.fc9.weight.requires_grad = False\n",
    "        self.fc9.bias.requires_grad = False\n",
    "\n",
    "        self.fc10.weight.requires_grad = False\n",
    "        self.fc10.bias.requires_grad = False\n",
    "\n",
    "        self.fc11.weight.requires_grad = False\n",
    "        self.fc11.bias.requires_grad = False\n",
    "\n",
    "        self.fc12.weight.requires_grad = False\n",
    "        self.fc12.bias.requires_grad = False\n",
    "\n",
    "        self.fc13.weight.requires_grad = False\n",
    "        self.fc13.bias.requires_grad = False\n",
    "\n",
    "        self.fc14.weight.requires_grad = False\n",
    "        self.fc14.bias.requires_grad = False\n",
    "\n",
    "        self.fc15.weight.requires_grad = False\n",
    "        self.fc15.bias.requires_grad = False\n",
    "\n",
    "        self.fc16.weight.requires_grad = False\n",
    "        self.fc16.bias.requires_grad = False\n",
    "\n",
    "        self.fc17.weight.requires_grad = False\n",
    "        self.fc17.bias.requires_grad = False\n",
    "\n",
    "        self.fc18.weight.requires_grad = False\n",
    "        self.fc18.bias.requires_grad = False\n",
    "\n",
    "        self.n_classes = num_classes\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## Define input mask\n",
    "        in_mask = torch.zeros(self.hidden_size, self.input_size).to(device)\n",
    "        in_mask[start_V1_L4_Pyr:end_V1_L4_Pyr,0] = 1\n",
    "        in_mask[start_V1_L4_SST:end_V1_L4_SST,1] = 1\n",
    "        in_mask[start_V1_L4_VIP:end_V1_L4_VIP,2] = 1\n",
    "\n",
    "        in_mask[start_V1_L23_Pyr:end_V1_L23_Pyr,3] = 1\n",
    "        in_mask[start_V1_L23_SST:end_V1_L23_SST,4] = 1\n",
    "        in_mask[start_V1_L23_VIP:end_V1_L23_VIP,5] = 1\n",
    "\n",
    "        in_mask[start_V1_L5_Pyr:end_V1_L5_Pyr,6] = 1\n",
    "        in_mask[start_V1_L5_SST:end_V1_L5_SST,7] = 1\n",
    "        in_mask[start_V1_L5_VIP:end_V1_L5_VIP,8] = 1\n",
    "\n",
    "        in_mask[start_LM_L4_Pyr:end_LM_L4_Pyr,9] = 1\n",
    "        in_mask[start_LM_L4_SST:end_LM_L4_SST,10] = 1\n",
    "        in_mask[start_LM_L4_VIP:end_LM_L4_VIP,11] = 1\n",
    "\n",
    "        in_mask[start_LM_L23_Pyr:end_LM_L23_Pyr,12] = 1\n",
    "        in_mask[start_LM_L23_SST:end_LM_L23_SST,13] = 1\n",
    "        in_mask[start_LM_L23_VIP:end_LM_L23_VIP,14] = 1\n",
    "\n",
    "        in_mask[start_LM_L5_Pyr:end_LM_L5_Pyr,15] = 1\n",
    "        in_mask[start_LM_L5_SST:end_LM_L5_SST,16] = 1\n",
    "        in_mask[start_LM_L5_VIP:end_LM_L5_VIP,17] = 1\n",
    "\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        nSamp, inDim, nSteps = x.shape\n",
    "\n",
    "        ops = torch.zeros(nSamp,nSteps,self.hidden_size, requires_grad=False).to(self.device)\n",
    "\n",
    "        pred1 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred2 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred3 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred4 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred5 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred6 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred7 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred8 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred9 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "\n",
    "        pred10 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred11 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred12 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred13 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred14 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred15 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred16 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred17 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "        pred18 = torch.zeros(nSamp,nSteps,self.n_classes, requires_grad=False).to(self.device)\n",
    "\n",
    "        for ii in range(nSteps):\n",
    "            ## Apply input mask\n",
    "            self.rnn.weight_ih_l0.data.mul(in_mask)\n",
    "\n",
    "            ip = torch.unsqueeze(x[:,:,ii],-1).view(nSamp,1,inDim)\n",
    "            op, ht = self.rnn(ip,h0) ## pass 1 timestep through RNN\n",
    "            fr_mask = ht.clone()>0\n",
    "            htt = fr_mask*ht.clone() ## mask firing rate\n",
    "            h0 = htt ## update hidden state\n",
    "            ops[:,ii,:] = torch.squeeze(op.clone())\n",
    "\n",
    "            ## Final prediction at every timestep\n",
    "            pred1[:,ii,:] = self.fc1(ops[:, ii, start_V1_L4_Pyr:end_V1_L4_Pyr].clone())\n",
    "            pred2[:,ii,:] = self.fc2(ops[:, ii, start_V1_L4_SST:end_V1_L4_SST].clone())\n",
    "            pred3[:,ii,:] = self.fc3(ops[:, ii, start_V1_L4_VIP:end_V1_L4_VIP].clone())\n",
    "            pred4[:,ii,:] = self.fc4(ops[:, ii, start_V1_L23_Pyr:end_V1_L23_Pyr].clone())\n",
    "            pred5[:,ii,:] = self.fc5(ops[:, ii, start_V1_L23_SST:end_V1_L23_SST].clone())\n",
    "            pred6[:,ii,:] = self.fc6(ops[:, ii, start_V1_L23_VIP:end_V1_L23_VIP].clone())\n",
    "            pred7[:,ii,:] = self.fc7(ops[:, ii, start_V1_L5_Pyr:end_V1_L5_Pyr].clone())\n",
    "            pred8[:,ii,:] = self.fc8(ops[:, ii, start_V1_L5_SST:end_V1_L5_SST].clone())\n",
    "            pred9[:,ii,:] = self.fc9(ops[:, ii, start_V1_L5_VIP:end_V1_L5_VIP].clone())\n",
    "\n",
    "            pred10[:,ii,:] = self.fc10(ops[:, ii, start_LM_L4_Pyr:end_LM_L4_Pyr].clone())\n",
    "            pred11[:,ii,:] = self.fc11(ops[:, ii, start_LM_L4_SST:end_LM_L4_SST].clone())\n",
    "            pred12[:,ii,:] = self.fc12(ops[:, ii, start_LM_L4_VIP:end_LM_L4_VIP].clone())\n",
    "            pred13[:,ii,:] = self.fc13(ops[:, ii, start_LM_L23_Pyr:end_LM_L23_Pyr].clone())\n",
    "            pred14[:,ii,:] = self.fc14(ops[:, ii, start_LM_L23_SST:end_LM_L23_SST].clone())\n",
    "            pred15[:,ii,:] = self.fc15(ops[:, ii, start_LM_L23_VIP:end_LM_L23_VIP].clone())\n",
    "            pred16[:,ii,:] = self.fc16(ops[:, ii, start_LM_L5_Pyr:end_LM_L5_Pyr].clone())\n",
    "            pred17[:,ii,:] = self.fc17(ops[:, ii, start_LM_L5_SST:end_LM_L5_SST].clone())\n",
    "            pred18[:,ii,:] = self.fc18(ops[:, ii, start_LM_L5_VIP:end_LM_L5_VIP].clone())\n",
    "\n",
    "        out1 = pred1.clone() #Take the output from the last time step\n",
    "        out2 = pred2.clone() #Take the output from the last time step\n",
    "        out3 = pred3.clone() #Take the output from the last time step\n",
    "        out4 = pred4.clone() #Take the output from the last time step\n",
    "        out5 = pred5.clone() #Take the output from the last time step\n",
    "        out6 = pred6.clone() #Take the output from the last time step\n",
    "        out7 = pred7.clone() #Take the output from the last time step\n",
    "        out8 = pred8.clone() #Take the output from the last time step\n",
    "        out9 = pred9.clone() #Take the output from the last time step\n",
    "\n",
    "        out10 = pred10.clone() #Take the output from the last time step\n",
    "        out11 = pred11.clone() #Take the output from the last time step\n",
    "        out12 = pred12.clone() #Take the output from the last time step\n",
    "        out13 = pred13.clone() #Take the output from the last time step\n",
    "        out14 = pred14.clone() #Take the output from the last time step\n",
    "        out15 = pred15.clone() #Take the output from the last time step\n",
    "        out16 = pred16.clone() #Take the output from the last time step\n",
    "        out17 = pred17.clone() #Take the output from the last time step\n",
    "        out18 = pred18.clone() #Take the output from the last time step\n",
    "\n",
    "        return torch.dstack((out1,out2, out3, out4, out5, out6, out7, out8, out9,\n",
    "                             out10,out11, out12, out13, out14, out15, out16, out17, out18)), htt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a39d6c-9e6c-446f-a98c-d8bda96797a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "optimizer = {}\n",
    "scheduler = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e06c4e-a8bc-4ba9-af36-4d3d248b793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "eta = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41864892-9506-4241-b140-1a56409a991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    model[cntr] = CelltypeRNN(18, N, 1, device)\n",
    "    model[cntr].to(device)\n",
    "    optimizer[cntr] = torch.optim.Adam(model[cntr].parameters(), lr=eta)\n",
    "    scheduler[cntr] = CosineAnnealingLR(optimizer[cntr], T_max=10, eta_min=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47cc7d-67ed-47e0-a7cc-3aa4ea1f8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = np.tile([1,-1, -1], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075aa5d4-dc20-42b4-85d9-eda03fc13b4e",
   "metadata": {},
   "source": [
    "#### Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bcd2ee-b6db-4ba0-b1ec-745dcea0f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(N, index_ranges, signs):\n",
    "    weights = np.zeros((N, N))\n",
    "    for ii, (start, end) in enumerate(index_ranges):\n",
    "        limit = 1 / np.sqrt(N) if signs[ii] == 1 else -1/np.sqrt(N)\n",
    "        weights[:, start:end] = np.random.uniform(0, limit, size=(N, end-start))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e76d4-f4b5-465f-8b31-355b7952514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(weights, index_ranges, signs):\n",
    "    mask = np.zeros_like(weights)\n",
    "    for i, (start, end) in enumerate(index_ranges):\n",
    "        if signs[i] == 1:\n",
    "            mask[:, start:end] = np.where(weights[:, start:end] > 0, 1, 0)\n",
    "        elif signs[i] == -1:\n",
    "            mask[:, start:end] = np.where(weights[:, start:end] < 0, 1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7473c-1a86-48b4-8edf-345e6b41c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ranges = [(start_V1_L4_Pyr,end_V1_L4_Pyr),(start_V1_L4_SST,end_V1_L4_SST),(start_V1_L4_VIP,end_V1_L4_VIP),\n",
    "                (start_V1_L23_Pyr,end_V1_L23_Pyr),(start_V1_L23_SST,end_V1_L23_SST),(start_V1_L23_VIP,end_V1_L23_VIP),\n",
    "                (start_V1_L5_Pyr,end_V1_L5_Pyr),(start_V1_L5_SST,end_V1_L5_SST),(start_V1_L5_VIP,end_V1_L5_VIP),\n",
    "                (start_LM_L4_Pyr,end_LM_L4_Pyr),(start_LM_L4_SST,end_LM_L4_SST),(start_LM_L4_VIP,end_LM_L4_VIP),\n",
    "                (start_LM_L23_Pyr,end_LM_L23_Pyr),(start_LM_L23_SST,end_LM_L23_SST),(start_LM_L23_VIP,end_LM_L23_VIP),\n",
    "                (start_LM_L5_Pyr,end_LM_L5_Pyr),(start_LM_L5_SST,end_LM_L5_SST),(start_LM_L5_VIP,end_LM_L5_VIP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792575a-dff1-4996-8ce8-bdef19b96b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_init = {}\n",
    "for cntr in range(nRuns):\n",
    "    weights_init[cntr] = initialize_weights(N,index_ranges,signs)\n",
    "    model[cntr].rnn.weight_hh_l0.data = torch.from_numpy(weights_init[cntr]).float()\n",
    "    torch.save(model[cntr].state_dict(),pp_pts[cntr]+'celltypeRNN-dale-initial-'+str(latent_scaling)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea011f-018e-4e83-aab5-b33d9d346ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 0\n",
    "plt.imshow(weights_init[kk])\n",
    "plt.colorbar()\n",
    "plt.title('Initial Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089470d6-6870-4483-ad4e-f189a12beff6",
   "metadata": {},
   "source": [
    "#### Test data pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfb3ff-a74a-41f7-9a9a-595a7b1c7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in train_loader[cntr]:\n",
    "    if train_on_gpu:\n",
    "        inputs, targets = inputs.float().cuda(), targets.float().cuda()\n",
    "        inputs = inputs.permute(0,2,1)\n",
    "        targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17]))\n",
    "        model[cntr].cuda()\n",
    "    else:\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        inputs = inputs.permute(0,2,1)\n",
    "        targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2,:],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5,:],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8,:],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11,:],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14,:],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038261f-df45-45ca-bd27-e222a9c1003f",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcaa4e9-ad70-48e2-9b81-643442c47ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 ##100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f2d35-d862-488a-a780-9e65798d89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_celltype = {}\n",
    "train_losses = {}\n",
    "for cntr in range(nRuns):\n",
    "    train_losses[cntr] = np.zeros(n_epochs)\n",
    "    for nn in range(n_cell_types):\n",
    "        train_losses_celltype[cntr,nn] = np.zeros(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4cb589-8159-425e-bbbb-bff55ffc6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_f_batch = {}\n",
    "inputs_batch = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed6b4a0-da68-4c6d-81ea-3b37276876da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    print(f'Run: {cntr}')\n",
    "    model[cntr].train()\n",
    "    train_loss_min = np.Inf\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader[cntr]:\n",
    "            if train_on_gpu:\n",
    "                inputs, targets = inputs.float().cuda(), targets.float().cuda()\n",
    "                inputs = inputs.permute(0,2,1)\n",
    "                targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17]))\n",
    "                model[cntr].cuda()\n",
    "            else:\n",
    "                inputs, targets = inputs.float(), targets.float()\n",
    "                inputs = inputs.permute(0,2,1)\n",
    "                targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17]))\n",
    "\n",
    "            optimizer[cntr].zero_grad()\n",
    "            outputs, firing_rates = model[cntr](inputs)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            if train_on_gpu:\n",
    "                outputs = outputs.cuda()\n",
    "\n",
    "            loss = criterion(outputs, targets_f)\n",
    "            train_loss += loss.item() #update training loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer[cntr].step()\n",
    "\n",
    "            ## Dale's backprop\n",
    "            w = model[cntr].rnn.weight_hh_l0.detach().cpu().numpy()\n",
    "            mask = generate_mask(w, index_ranges, signs)\n",
    "            wm = w*mask\n",
    "            model[cntr].rnn.weight_hh_l0.data = torch.from_numpy(wm).float().cuda()\n",
    "\n",
    "        if train_loss< train_loss_min:\n",
    "\n",
    "            #print('Epoch: {}, Train Loss Decreased!! ({:.6f}-->{:.6f})'.format(epoch,train_loss_min,train_loss))\n",
    "            train_loss_min = train_loss\n",
    "            torch.save(model[cntr].state_dict(),pp_pts[cntr]+'celltypeRNN-dale-dense-'+str(latent_scaling)+'.pt')\n",
    "\n",
    "        for nnn in range(n_cell_types):\n",
    "            train_losses_celltype[cntr,nnn][epoch-1] = criterion(outputs[:,:,nnn], targets_f[:,:,nnn])\n",
    "\n",
    "        train_losses[cntr] = train_loss\n",
    "\n",
    "        scheduler[cntr].step()\n",
    "\n",
    "        targets_f_batch[cntr] = targets_f\n",
    "        inputs_batch[cntr] = inputs\n",
    "\n",
    "        if epoch%2 == 0:\n",
    "            print(f'Epoch: {epoch}')\n",
    "            print(f'Train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efecff-bbd1-4063-8972-45cc959f07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 3\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Individual Training Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "for ii in range(n_cell_types):\n",
    "    if ii < np.round(n_cell_types//2):\n",
    "        plt.plot(train_losses_celltype[run,ii],'-',label=label_arr[ii])\n",
    "    else:\n",
    "        plt.plot(train_losses_celltype[run,ii],'--',label=label_arr[ii])\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c7836-3a92-4637-82dd-ba07f00cafaf",
   "metadata": {},
   "source": [
    "#### Visualize traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb0b1d-f6da-46a7-adb3-a75d9a885775",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_np = outputs.detach().cpu().numpy()\n",
    "targets_np = targets_f.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2315a85-3125-4dd1-afac-908faaa4aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 2\n",
    "ii = 10\n",
    "\n",
    "# target_batch = targets_np[ii*batch_size:(ii+1)*batch_size]\n",
    "target_curve = targets_np[ex,:,ii]\n",
    "plt.plot(target_curve,color='k',label='Ground truth')\n",
    "\n",
    "# output_batch = outputs_np[ii*batch_size:(ii+1)*batch_size]\n",
    "output_curve = outputs_np[ex,:,ii]\n",
    "plt.plot(output_curve, color='r',label='Recon')\n",
    "plt.legend()\n",
    "plt.title(label_arr[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a1954-5589-494a-82a6-a557c86820d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 0\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "for ii in range(n_cell_types):\n",
    "    plt.subplot(6,3,ii+1)\n",
    "\n",
    "    target_curve = targets_np[ex,:,ii]\n",
    "    plt.plot(target_curve,color='k')\n",
    "\n",
    "    output_curve = outputs_np[ex,:,ii]\n",
    "    plt.plot(output_curve,color='r')\n",
    "\n",
    "    plt.title(label_arr[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a522c0-5a80-4037-96f6-03cd6491f4fa",
   "metadata": {},
   "source": [
    "#### Visualize connectivity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2907b-db1c-4190-83fb-679d1de51b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mtx_final = {}\n",
    "conn_mtx_init = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02419815-8b46-4dab-9533-96010b28e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    conn_mtx_init[cntr] = weights_init[cntr]\n",
    "    model[cntr].load_state_dict(torch.load(pp_pts[cntr]+'celltypeRNN-dale-dense-'+str(latent_scaling)+'.pt'))\n",
    "    conn_mtx_final[cntr] = (model[cntr].rnn._parameters['weight_hh_l0'].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f332e92-d9eb-4435-b67d-37b3234bc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = plt.figure(figsize=(12,5))\n",
    "\n",
    "run = 0\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(conn_mtx_init[run])\n",
    "plt.title(\"Init\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(conn_mtx_final[run])\n",
    "plt.title(\"Final\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a472966-7bab-45bc-9838-d017ea5ffbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(conn_mtx_final[run]>0)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(conn_mtx_final[run]<0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f5f6a-90a3-40b2-beda-c1782d2d4ded",
   "metadata": {},
   "source": [
    "#### Average weights in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e791f-faab-4a7a-97d7-7c6a0ebe6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights_in_blocks_matrix(weight_matrix, block_indices, use_absolute_values=False):\n",
    "    n_blocks = len(block_indices)\n",
    "    averages_matrix = np.zeros((n_blocks, n_blocks))\n",
    "\n",
    "    for i, (start_i, end_i) in enumerate(block_indices):\n",
    "        for j, (start_j, end_j) in enumerate(block_indices):\n",
    "            block_weights = weight_matrix[start_i:end_i, start_j:end_j]  # Extract the block of weights ##had +1 at end_js\n",
    "\n",
    "            if use_absolute_values:\n",
    "                block_weights = np.abs(block_weights)\n",
    "\n",
    "            block_average = np.mean(block_weights)  # Calculate the average\n",
    "            averages_matrix[i, j] = block_average\n",
    "\n",
    "    return averages_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f9f91-fa71-4c78-a462-5010e1cb9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_indices = [(start_V1_L4_Pyr,end_V1_L4_Pyr), (start_V1_L4_SST,end_V1_L4_SST), (start_V1_L4_VIP,end_V1_L4_VIP),\n",
    "                 (start_V1_L23_Pyr,end_V1_L23_Pyr), (start_V1_L23_SST,end_V1_L23_SST), (start_V1_L23_VIP,end_V1_L23_VIP),\n",
    "                 (start_V1_L5_Pyr,end_V1_L5_Pyr), (start_V1_L5_SST,end_V1_L5_SST), (start_V1_L5_VIP,end_V1_L5_VIP),\n",
    "                 (start_LM_L4_Pyr,end_LM_L4_Pyr), (start_LM_L4_SST,end_LM_L4_SST), (start_LM_L4_VIP,end_LM_L4_VIP),\n",
    "                 (start_LM_L23_Pyr,end_LM_L23_Pyr), (start_LM_L23_SST,end_LM_L23_SST), (start_LM_L23_VIP,end_LM_L23_VIP),\n",
    "                 (start_LM_L5_Pyr,end_LM_L5_Pyr), (start_LM_L5_SST,end_LM_L5_SST), (start_LM_L5_VIP,end_LM_L5_VIP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed77d3-102e-4a56-a4e5-5ee509eac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_indices_layers = [(start_V1_L4_Pyr,end_V1_L4_VIP), (start_V1_L23_Pyr,end_V1_L23_VIP), (start_V1_L5_Pyr,end_V1_L5_VIP),\n",
    "                        (start_LM_L4_Pyr,end_LM_L4_VIP), (start_LM_L23_Pyr,end_LM_L23_VIP), (start_LM_L5_Pyr,end_LM_L5_VIP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645677ed-78ef-41e4-81bb-c59f22e00b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr_layers = ['V1_L4', 'V1_L23', 'V1_L5', 'LM_L4', 'LM_L23', 'LM_L5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd423de-0512-4342-b6a2-b1bea19dd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_indices_areas = [(start_V1_L4_Pyr,end_V1_L5_VIP), (start_LM_L4_Pyr,end_LM_L5_VIP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaeb7b0-978b-44ec-9d7b-ba4a36bf9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr_areas = ['V1','LM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f503b1-b631-41af-940d-c2e852b13892",
   "metadata": {},
   "source": [
    "#### Read in connection probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6e540-c26d-42d6-8973-9416ad9ed5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.read_csv('/content/drive/MyDrive/Aish_celltypeRNN/frozen-readout-celltype-training/connection-probs-full.csv',header=None))\n",
    "conn_df = df[(df[1] != 'L6') & (df[2] != 'L6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d2bbc2-0d91-4c9b-ab2c-bc7f6fca67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7edb561-e490-457d-adfa-fcccfab4f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = ['Pyr', 'SST', 'ViP']\n",
    "layers = ['L4','L2/3','L5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fa262-25d9-4225-a23c-6e3b1b161726",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = []\n",
    "for ii, layer in enumerate(layers):\n",
    "    for jj, cell in enumerate(cell_types):\n",
    "        pop = layer + ': ' + cell\n",
    "        combos.append(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c20cf4-90e7-4558-ba1c-ea0a94e66d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_probs = np.zeros((len(combos),len(combos)))\n",
    "for col, pre_syn in enumerate(combos):\n",
    "    for row, post_syn in enumerate(combos):\n",
    "        conn_probs[row, col] = float(conn_df[(conn_df[5] == pre_syn) & (conn_df[6] == post_syn)].iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd952e12-747b-4402-b51e-d139472bf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsities = 1-conn_probs\n",
    "print('Connection probs: ',conn_probs)\n",
    "print('Sparsities: ',sparsities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450c837-5c38-4f1d-b906-25a784997d37",
   "metadata": {},
   "source": [
    "#### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae039258-3440-44f3-8ddd-7709c84e40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo_noise_prune(A, s):\n",
    "\n",
    "    N_post = A.shape[0]\n",
    "    N_pre = A.shape[1]\n",
    "    A_sparse = np.zeros_like(A)\n",
    "\n",
    "    z0 = np.sum(A==0) + np.min((N_pre,N_post))\n",
    "    if z0 > 0:\n",
    "        z = s*np.prod(A.shape)\n",
    "        s = (z-z0)/(np.prod(A.shape)-z0)\n",
    "\n",
    "    if N_post == N_pre:\n",
    "        D = -1*np.diag(np.diag(A))\n",
    "        W = A #+ D\n",
    "    else:\n",
    "        d_vals = -1*np.diag(A)\n",
    "        D = np.zeros_like(A)\n",
    "        np.fill_diagonal(D, d_vals)\n",
    "        W = A #+ D\n",
    "\n",
    "    K = N_pre*N_post*(1-s)/np.sum(np.abs(W))\n",
    "\n",
    "    for ii in range(N_post):\n",
    "        for jj in range(N_pre):\n",
    "\n",
    "            if np.abs(W[ii,jj])>0:\n",
    "                Pij = K*(np.abs(W[ii,jj]))\n",
    "                if np.random.uniform() < Pij:\n",
    "                    A_sparse[ii,jj] = A[ii,jj]\n",
    "\n",
    "    return A_sparse, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8982d28-ae07-47d9-9209-57b02ff560f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_in_blocks(matrix, block_indices, etas_mat):\n",
    "    # Initialize the pruned matrix with zeros\n",
    "    A_block_pruned = np.zeros_like(matrix)\n",
    "    block_sparsities = -1*np.ones_like(etas_mat)\n",
    "\n",
    "    # Process each block and place it into A_pruned\n",
    "    for pre, (start_pre, end_pre) in enumerate(block_indices):\n",
    "        for post, (start_post, end_post) in enumerate(block_indices):\n",
    "\n",
    "            # Extract the block from the original matrix\n",
    "            block = matrix[start_post:end_post, start_pre:end_pre]\n",
    "            # Process the block using the prune function\n",
    "            pruned_block, _ = topo_noise_prune(block, etas_mat[post,pre])\n",
    "            # Place the pruned block into the pruned matrix\n",
    "            A_block_pruned[start_post:end_post, start_pre:end_pre] = pruned_block\n",
    "\n",
    "            block_sparsities[post,pre] = np.sum(pruned_block==0)/np.prod(pruned_block.shape)\n",
    "\n",
    "    return A_block_pruned, block_sparsities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b7b32-a389-48af-887d-7f25445b8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_indices_V1 = []\n",
    "\n",
    "ss = 0\n",
    "for ii, layer in enumerate(layers):\n",
    "    for jj, cell in enumerate(cell_types):\n",
    "        ee = ss + pop_list_types[jj]*latent_scaling\n",
    "        intra_indices_V1.append((ss,ee))\n",
    "        ss = ee\n",
    "\n",
    "intra_indices_V1 = np.array(intra_indices_V1)\n",
    "intra_indices_LM = intra_indices_V1 + n_depths*sum(pop_list_types)*latent_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19d377-d278-4057-a672-a3b3aaa2dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "V1_block_pruned = {}\n",
    "V1_block_sparsities = {}\n",
    "\n",
    "LM_block_pruned = {}\n",
    "LM_block_sparsities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed611948-8799-4782-8f59-9de75233072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process blocks and get the pruned intra-areal connectivity matrix\n",
    "for cntr in range(nRuns):\n",
    "    V1_block_pruned[cntr], V1_block_sparsities[cntr] = prune_in_blocks(conn_mtx_final[cntr], intra_indices_V1, sparsities)\n",
    "    LM_block_pruned[cntr], LM_block_sparsities[cntr] = prune_in_blocks(conn_mtx_final[cntr], intra_indices_LM, sparsities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a824b-b794-4b73-88be-f49bf5d192e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mtx_final_pruned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650cfc8-68fc-4678-a3b5-9d9f5bab6eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    conn_mtx_final_pruned[cntr] = conn_mtx_final[cntr].copy()\n",
    "    conn_mtx_final_pruned[cntr][start_V1_L4_Pyr:end_V1_L5_VIP,\n",
    "                          start_V1_L4_Pyr:end_V1_L5_VIP] = V1_block_pruned[cntr][start_V1_L4_Pyr:end_V1_L5_VIP,\n",
    "                                                                            start_V1_L4_Pyr:end_V1_L5_VIP]\n",
    "    conn_mtx_final_pruned[cntr][start_LM_L4_Pyr:end_LM_L5_VIP,\n",
    "                          start_LM_L4_Pyr:end_LM_L5_VIP] = LM_block_pruned[cntr][start_LM_L4_Pyr:end_LM_L5_VIP,\n",
    "                                                                            start_LM_L4_Pyr:end_LM_L5_VIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd94d8f-4b29-4e25-bedc-3a9c1ea7ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_mask = {}\n",
    "for cntr in range(nRuns):\n",
    "    rnn_mask[cntr] = torch.from_numpy((conn_mtx_final_pruned[cntr]!=0).astype(int)).float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f214ee-2a91-4c86-b408-ea5e96981fc1",
   "metadata": {},
   "source": [
    "#### Define inter-areal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78744ec4-522b-4863-a0aa-586f913eec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "mask_inter_areal = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df554133-c652-4c30-9e68-0029c3b5c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    mask_inter_areal[cntr] = np.ones((N,N))\n",
    "\n",
    "    mask_inter_areal[cntr][start_LM_L4_Pyr:end_LM_L5_VIP, start_V1_L4_Pyr:end_V1_L5_VIP] = 0.\n",
    "    mask_inter_areal[cntr][start_V1_L4_Pyr:end_V1_L5_VIP, start_LM_L4_Pyr:end_LM_L5_VIP] = 0.\n",
    "\n",
    "    s1 = mask_inter_areal[cntr][start_LM_L4_Pyr:end_LM_L4_VIP, start_V1_L23_Pyr:end_V1_L23_Pyr].shape\n",
    "    mask_inter_areal[cntr][start_LM_L4_Pyr:end_LM_L4_VIP, start_V1_L23_Pyr:end_V1_L23_Pyr] = np.random.binomial(1, p, size=s1)\n",
    "\n",
    "    s2 = mask_inter_areal[cntr][start_V1_L23_Pyr:end_V1_L23_VIP, start_LM_L5_Pyr:end_LM_L5_Pyr].shape\n",
    "    mask_inter_areal[cntr][start_V1_L23_Pyr:end_V1_L23_VIP, start_LM_L5_Pyr:end_LM_L5_Pyr] = np.random.binomial(1, p, size=s2)\n",
    "\n",
    "    s3 = mask_inter_areal[cntr][start_V1_L5_Pyr:end_V1_L5_VIP, start_LM_L5_Pyr:end_LM_L5_Pyr].shape\n",
    "    mask_inter_areal[cntr][start_V1_L5_Pyr:end_V1_L5_VIP, start_LM_L5_Pyr:end_LM_L5_Pyr] = np.random.binomial(1, p, size=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8fb94-8ef4-446b-8f86-b594a130f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_inter_areal[0], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd88f12-623d-41ec-bbdb-6bcdc30e9e68",
   "metadata": {},
   "source": [
    "#### Substitute weights with single shot pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0ed71-c134-4251-a378-5e1afdcaa44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pruned = {}\n",
    "for cntr in range(nRuns):\n",
    "    model_pruned[cntr] = model[cntr]\n",
    "    model_pruned[cntr] = model_pruned[cntr].cuda()\n",
    "    model_pruned[cntr].rnn.weight_hh_l0.data = model_pruned[cntr].rnn.weight_hh_l0.data.copy_(torch.from_numpy(conn_mtx_final_pruned[cntr]*mask_inter_areal[cntr]).float().cuda())\n",
    "    model_pruned[cntr] = model_pruned[cntr].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78fc49-8eb5-4833-97b1-837255bab618",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inter_areal_tensor = {}\n",
    "for cntr in range(nRuns):\n",
    "    mask_inter_areal_tensor[cntr] = torch.from_numpy(mask_inter_areal[cntr])\n",
    "    if train_on_gpu:\n",
    "        mask_inter_areal_tensor[cntr] = mask_inter_areal_tensor[cntr].float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f2834-85cc-49cb-9a25-e98c00108523",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "for cntr in range(nRuns):\n",
    "    op, frp = model_pruned[cntr](inputs_batch[cntr])\n",
    "    op = torch.squeeze(op)\n",
    "    errors[cntr] = criterion(op.cuda(), targets_f_batch[cntr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec908aec-31a6-49aa-b587-2ae7da42bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee304e-58c3-4efd-af92-52a72f8bd9ef",
   "metadata": {},
   "source": [
    "#### Fine-tune and retrain weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f27ab-72d2-470a-8613-7661bc51a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_optimizer = {}\n",
    "finetune_scheduler = {}\n",
    "for cntr in range(nRuns):\n",
    "    finetune_optimizer[cntr] = optim.Adam(model_pruned[cntr].parameters(), lr=0.001)\n",
    "    finetune_scheduler[cntr] = CosineAnnealingLR(finetune_optimizer[cntr], T_max=10, eta_min=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed949f79-7a10-4f36-8e6b-0e2b6161f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs_finetune = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c532d8-ff27-416e-ae14-fe13834e0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_pruned = {}\n",
    "train_losses_celltype_pruned = {}\n",
    "\n",
    "for cntr in range(nRuns):\n",
    "    train_losses_pruned[cntr] = np.zeros(n_epochs_finetune)\n",
    "    for nnn in range(n_cell_types):\n",
    "        train_losses_celltype_pruned[cntr,nnn] = np.zeros(n_epochs_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f40162-a4c8-42d9-9fe8-a636bc4078b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    print(f'Run: {cntr}')\n",
    "    model_pruned[cntr].train()\n",
    "    train_loss_min = errors[cntr]\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs_finetune+1)):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader[cntr]:\n",
    "            if train_on_gpu:\n",
    "                inputs, targets = inputs.float().cuda(), torch.unsqueeze(targets.float().cuda(),-1)\n",
    "                inputs = inputs.permute(0,2,1)\n",
    "                targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17]))\n",
    "                model_pruned[cntr].cuda()\n",
    "            else:\n",
    "                inputs, targets = inputs.float(), torch.unsqueeze(targets.float(),-1)\n",
    "                inputs = inputs.permute(0,2,1)\n",
    "                targets_f = torch.dstack((torch.squeeze(targets)[:,:,0],torch.squeeze(targets)[:,:,1],torch.squeeze(targets)[:,:,2],\n",
    "                                  torch.squeeze(targets)[:,:,3],torch.squeeze(targets)[:,:,4],torch.squeeze(targets)[:,:,5],\n",
    "                                  torch.squeeze(targets)[:,:,6],torch.squeeze(targets)[:,:,7],torch.squeeze(targets)[:,:,8],\n",
    "                                  torch.squeeze(targets)[:,:,9],torch.squeeze(targets)[:,:,10],torch.squeeze(targets)[:,:,11],\n",
    "                                  torch.squeeze(targets)[:,:,12],torch.squeeze(targets)[:,:,13],torch.squeeze(targets)[:,:,14],\n",
    "                                  torch.squeeze(targets)[:,:,15],torch.squeeze(targets)[:,:,16],torch.squeeze(targets)[:,:,17]))\n",
    "\n",
    "            finetune_optimizer[cntr].zero_grad()\n",
    "            oops, frps = model_pruned[cntr](inputs)\n",
    "            oops = torch.squeeze(oops)\n",
    "            if train_on_gpu:\n",
    "                oops = oops.cuda()\n",
    "            loss = criterion(oops, targets_f)\n",
    "            loss.backward()\n",
    "            finetune_optimizer[cntr].step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            ## Dale's backprop\n",
    "            w = model_pruned[cntr].rnn.weight_hh_l0.detach().cpu().numpy()\n",
    "            mask = generate_mask(w, index_ranges, signs)\n",
    "            wm = w*mask\n",
    "            model_pruned[cntr].rnn.weight_hh_l0.data = torch.from_numpy(wm).float().cuda()\n",
    "\n",
    "            ## make sure sparsity mask is applied\n",
    "            model_pruned[cntr].rnn.weight_hh_l0.data = rnn_mask[cntr]*mask_inter_areal_tensor[cntr]*model_pruned[cntr].rnn.weight_hh_l0.data\n",
    "\n",
    "        if train_loss< train_loss_min:\n",
    "\n",
    "            #print('Epoch: {}, Train Loss Decreased!! ({:.6f}-->{:.6f})'.format(epoch,train_loss_min,train_loss))\n",
    "            train_loss_min = train_loss\n",
    "            torch.save(model[cntr].state_dict(),pp_pts[cntr]+'celltypeRNN-dale-sparse-'+str(latent_scaling)+'.pt')\n",
    "\n",
    "        for nnn in range(n_cell_types):\n",
    "            train_losses_celltype_pruned[cntr,nnn][epoch-1] = criterion(oops[:,:,nnn], targets_f[:,:,nnn])\n",
    "\n",
    "        train_losses_pruned[cntr] = train_loss\n",
    "\n",
    "        finetune_scheduler[cntr].step()\n",
    "\n",
    "        if epoch%2 == 0:\n",
    "            print(f'Epoch: {epoch}')\n",
    "            print(f'Train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1160f9-f69c-4384-8efd-34cbdc088f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "oops_np = oops.detach().cpu().numpy()\n",
    "targets_np = targets_f.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f448e7-e2fe-4e09-8f84-7ec436a46420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 10\n",
    "\n",
    "plt.figure(figsize=(24,20))\n",
    "\n",
    "for ii in range(n_cell_types):\n",
    "    plt.subplot(6,3,ii+1)\n",
    "\n",
    "    target_curve = targets_np[ex,:,ii]\n",
    "    plt.plot(target_curve,color='k')\n",
    "\n",
    "    output_curve = oops_np[ex,:,ii]\n",
    "    plt.plot(output_curve,color='r')\n",
    "\n",
    "    plt.title(label_arr[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34520761-0583-4144-b066-c4a2a11b6eee",
   "metadata": {},
   "source": [
    "#### Weight analysis post pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781b571-1d6d-4057-ac24-e4c4a5c117b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_mtx_final_pruned_retrained = {}\n",
    "conn_mtx_pruned_init = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56befab-615f-44d7-ade9-85dfc1297690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    conn_mtx_final_pruned_retrained[cntr] = (model_pruned[cntr].rnn._parameters['weight_hh_l0'].cpu().detach().numpy())\n",
    "    conn_mtx_pruned_init[cntr] = conn_mtx_final_pruned[cntr]*mask_inter_areal[cntr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f893f-736e-43ab-9af6-37f0b08253c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = (mask_inter_areal[run]!=0)*1\n",
    "plt.imshow(MM, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5b255-027e-4f87-ba59-4d1835c0b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0\n",
    "\n",
    "ff = plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.abs(conn_mtx_pruned_init[run]),interpolation='nearest')\n",
    "plt.title(\"Init\")\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.04)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(conn_mtx_final_pruned_retrained[run]),interpolation='nearest')\n",
    "plt.title(\"Final\")\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba5158-9425-4d2d-aa6f-4370558bc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_raw_init_pruned = {}\n",
    "av_raw_final_pruned = {}\n",
    "\n",
    "av_abs_init_pruned = {}\n",
    "av_abs_final_pruned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d0242-0a06-40a7-a6aa-b4ac685eb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    av_raw_init_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices, use_absolute_values=False)\n",
    "    av_raw_final_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices,\n",
    "                                                           use_absolute_values=False)\n",
    "\n",
    "    av_abs_init_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices, use_absolute_values=True)\n",
    "    av_abs_final_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices,\n",
    "                                                           use_absolute_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9273a-7291-4922-8ec5-90fa886a5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraw = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_raw_init_pruned[run], cmap='viridis', vmin=av_raw_init_pruned[run].min(), vmax=av_raw_init_pruned[run].max())\n",
    "plt.title('Init - Raw')\n",
    "plt.xticks(np.arange(len(label_arr)), label_arr, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr)), label_arr)\n",
    "plt.colorbar()\n",
    "plt.clim(-0.025,0.03)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_raw_final_pruned[run], cmap='viridis', vmin=av_raw_final_pruned[run].min(), vmax=av_raw_final_pruned[run].max())\n",
    "plt.title('Final - Raw')\n",
    "plt.xticks(np.arange(len(label_arr)), label_arr, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr)), label_arr)\n",
    "plt.colorbar()\n",
    "plt.clim(-0.025,0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf80aa3-1e9d-4cd1-99e1-b67d769b704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabs = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_abs_init_pruned[run], cmap='viridis', vmin=av_abs_init_pruned[run].min(), vmax=av_abs_init_pruned[run].max())\n",
    "plt.title('Init - Abs')\n",
    "plt.xticks(np.arange(len(label_arr)), label_arr, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr)), label_arr)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.015)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_abs_final_pruned[run], cmap='viridis', vmin=av_abs_final_pruned[run].min(), vmax=av_abs_final_pruned[run].max())\n",
    "plt.title('Final - Abs')\n",
    "plt.xticks(np.arange(len(label_arr)), label_arr, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr)), label_arr)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc5706-2955-4864-8e81-c56179d838b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_raw_init_layers_pruned = {}\n",
    "av_raw_final_layers_pruned = {}\n",
    "\n",
    "av_abs_init_layers_pruned = {}\n",
    "av_abs_final_layers_pruned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3b115-267c-444b-95d4-81248339c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    av_raw_init_layers_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices_layers, use_absolute_values=False)\n",
    "    av_raw_final_layers_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices_layers, use_absolute_values=False)\n",
    "\n",
    "    av_abs_init_layers_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices_layers, use_absolute_values=True)\n",
    "    av_abs_final_layers_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices_layers, use_absolute_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5772fe-80bf-4717-b22a-24411c2a8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraw = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_raw_init_layers_pruned[run], cmap='viridis',\n",
    "           vmin=av_raw_init_layers_pruned[run].min(), vmax=av_raw_init_layers_pruned[run].max(),interpolation='nearest')\n",
    "plt.title('Init - Raw')\n",
    "plt.xticks(np.arange(len(label_arr_layers)), label_arr_layers, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_layers)), label_arr_layers)\n",
    "plt.colorbar()\n",
    "# plt.clim(0.007,0.01)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_raw_final_layers_pruned[run], cmap='viridis',\n",
    "           vmin=av_raw_final_layers_pruned[run].min(), vmax=av_raw_final_layers_pruned[run].max(),interpolation='nearest')\n",
    "plt.title('Final - Raw')\n",
    "plt.xticks(np.arange(len(label_arr_layers)), label_arr_layers, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_layers)), label_arr_layers)\n",
    "plt.colorbar()\n",
    "# plt.clim(0.007,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37475d2-0d11-4a39-80ad-0fd863b87807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabs = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_abs_init_layers_pruned[run], cmap='viridis',\n",
    "           vmin=av_abs_init_layers_pruned[run].min(), vmax=av_abs_init_layers_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Init - Abs')\n",
    "plt.xticks(np.arange(len(label_arr_layers)), label_arr_layers, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_layers)), label_arr_layers)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.0042)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_abs_final_layers_pruned[run], cmap='viridis',\n",
    "           vmin=av_abs_final_layers_pruned[run].min(), vmax=av_abs_final_layers_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Final - Abs')\n",
    "plt.xticks(np.arange(len(label_arr_layers)), label_arr_layers, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_layers)), label_arr_layers)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.0042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4294ba7-7f4e-42ef-ac97-12b377a85d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_raw_init_areas_pruned = {}\n",
    "av_raw_final_areas_pruned = {}\n",
    "\n",
    "av_abs_init_areas_pruned = {}\n",
    "av_abs_final_areas_pruned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66120557-9aac-4a52-8593-a39de13995a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    av_raw_init_areas_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices_areas, use_absolute_values=False)\n",
    "    av_raw_final_areas_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices_areas, use_absolute_values=False)\n",
    "\n",
    "    av_abs_init_areas_pruned[cntr] = average_weights_in_blocks_matrix(weights_init[cntr], block_indices_areas, use_absolute_values=True)\n",
    "    av_abs_final_areas_pruned[cntr] = average_weights_in_blocks_matrix(conn_mtx_final_pruned_retrained[cntr], block_indices_areas, use_absolute_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db0983-c1ce-46db-a85f-057e466f4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraw = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_raw_init_areas_pruned[run], cmap='viridis',\n",
    "           vmin=av_raw_init_areas_pruned[run].min(), vmax=av_raw_init_areas_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Init - Raw')\n",
    "plt.xticks(np.arange(len(label_arr_areas)), label_arr_areas, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_areas)), label_arr_areas)\n",
    "plt.colorbar()\n",
    "# plt.clim(0.007,0.01)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_raw_final_areas_pruned[run], cmap='viridis',\n",
    "           vmin=av_raw_final_areas_pruned[run].min(), vmax=av_raw_final_areas_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Final - Raw')\n",
    "plt.xticks(np.arange(len(label_arr_areas)), label_arr_areas, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_areas)), label_arr_areas)\n",
    "plt.colorbar()\n",
    "# plt.clim(0.007,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d70309-10fc-4f5e-a45e-e46f76982fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fabs = plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(av_abs_init_areas_pruned[run], cmap='viridis',\n",
    "           vmin=av_abs_init_areas_pruned[run].min(), vmax=av_abs_init_areas_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Init - Abs')\n",
    "plt.xticks(np.arange(len(label_arr_areas)), label_arr_areas, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_areas)), label_arr_areas)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.0016)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(av_abs_final_areas_pruned[run], cmap='viridis',\n",
    "           vmin=av_abs_final_areas_pruned[run].min(), vmax=av_abs_final_areas_pruned[run].max(), interpolation='nearest')\n",
    "plt.title('Final - Abs')\n",
    "plt.xticks(np.arange(len(label_arr_areas)), label_arr_areas, rotation=70, ha='right')\n",
    "plt.yticks(np.arange(len(label_arr_areas)), label_arr_areas)\n",
    "plt.colorbar()\n",
    "plt.clim(0.0,0.0016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7a862-1ea0-400f-be19-afe23c24ad6e",
   "metadata": {},
   "source": [
    "#### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6139c00-16a5-449e-bfea-de8bd0803cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter_heat(matrix, labels):\n",
    "    # Ensure the input is a square matrix\n",
    "    assert matrix.shape[0] == matrix.shape[1], \"The input matrix must be square\"\n",
    "    assert matrix.shape[0] == len(labels), \"The number of labels must match the dimensions of the matrix\"\n",
    "\n",
    "    sources, targets, values = [], [], []\n",
    "\n",
    "    # Populate sources, targets, and values based on the matrix\n",
    "    for ii in range(matrix.shape[0]):\n",
    "        for jj in range(matrix.shape[1]):\n",
    "            sources.append(labels[jj]+'_source')\n",
    "            targets.append(labels[ii]+'_target')\n",
    "            values.append(matrix[ii,jj])\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'source': sources,\n",
    "        'target': targets,\n",
    "        'value': values\n",
    "    })\n",
    "\n",
    "    # Create the scatterplot heatmap diagram\n",
    "    # Draw each cell as a scatter point with varying size and color\n",
    "    g = sns.relplot(\n",
    "        data=data,\n",
    "        x=\"source\", y=\"target\", hue=\"value\", size=\"value\",\n",
    "        palette=\"binary\", edgecolor=\".7\")\n",
    "\n",
    "    # Tweak the figure to finalize\n",
    "    g.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\n",
    "    g.despine(left=True, bottom=True)\n",
    "    g.ax.margins(.02)\n",
    "    for label in g.ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbcd97-f725-4920-a427-373e750390e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_pop = np.zeros((nRuns,) + av_abs_final_pruned[0].shape)\n",
    "av_layers = np.zeros((nRuns,) + av_abs_final_layers_pruned[0].shape)\n",
    "av_areas = np.zeros((nRuns,) + av_abs_final_areas_pruned[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774a0ab-ea06-4f46-833d-c6cb6acf79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cntr in range(nRuns):\n",
    "    av_pop[cntr] = av_abs_final_pruned[cntr]\n",
    "    av_layers[cntr] = av_abs_final_layers_pruned[cntr]\n",
    "    av_areas[cntr] = av_abs_final_areas_pruned[cntr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace54567-9ce4-4fcd-b829-f53d39c893dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_pop = create_scatter_heat(np.mean(av_pop,0), label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ceabd-605a-4bfd-aba5-f8565d0f40b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_layers = create_scatter_heat(np.mean(av_layers,0), label_arr_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd96c8e-891a-4e99-b49a-49d6971301bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_areas = create_scatter_heat(np.mean(av_areas,0), label_arr_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95719b-71bb-49a9-ae45-f326f92fdab1",
   "metadata": {},
   "source": [
    "#### With dispersion and significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d278360-c060-4252-969e-174a87776319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dispersion_and_significance(data, dispersion_type):\n",
    "    \"\"\"\n",
    "    Calculate dispersion for each element across multiple runs and their significance.\n",
    "\n",
    "    Parameters:\n",
    "    - data: numpy array of shape (nRuns, val1, val2)\n",
    "    - dispersion_type: str, one of ['std', 'var', 'range', 'iqr', 'cv']\n",
    "\n",
    "    Returns:\n",
    "    - dispersion: numpy array of shape (val1, val2)\n",
    "    - significance: numpy array of p-values with shape (val1, val2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if input data is a numpy array\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        raise ValueError(\"Data should be a numpy array\")\n",
    "\n",
    "    # Check if the dispersion_type is valid\n",
    "    valid_types = ['std', 'var', 'range', 'iqr', 'cv']\n",
    "    if dispersion_type not in valid_types:\n",
    "        raise ValueError(f\"Dispersion type should be one of {valid_types}\")\n",
    "\n",
    "    # Initialize the output arrays\n",
    "    val1, val2 = data.shape[1], data.shape[2]\n",
    "    dispersion = np.zeros((val1, val2))\n",
    "    significance = np.zeros((val1, val2))\n",
    "\n",
    "    for ii in range(val1):\n",
    "        for jj in range(val2):\n",
    "            values = data[:, ii, jj]\n",
    "            if dispersion_type == 'std':\n",
    "                dispersion[ii, jj] = np.std(values)\n",
    "            elif dispersion_type == 'var':\n",
    "                dispersion[ii, jj] = np.var(values)\n",
    "            elif dispersion_type == 'range':\n",
    "                dispersion[ii, jj] = np.ptp(values)\n",
    "            elif dispersion_type == 'iqr':\n",
    "                dispersion[ii, jj] = np.percentile(values, 75) - np.percentile(values, 25)\n",
    "            elif dispersion_type == 'cv':\n",
    "                dispersion[ii, jj] = 1-np.std(values) / np.mean(values)\n",
    "\n",
    "            # Perform t-test for significance\n",
    "            t_stat, p_value = ttest_ind(values, values)\n",
    "            significance[ii, jj] = p_value\n",
    "\n",
    "    return dispersion, significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcd0c5-e8dd-4a15-980c-d0193a8a2c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_type = 'cv'\n",
    "disp_pop, sig_pop = calculate_dispersion_and_significance(av_pop, dispersion_type)\n",
    "disp_layers, sig_layers = calculate_dispersion_and_significance(av_layers, dispersion_type)\n",
    "disp_areas, sig_areas = calculate_dispersion_and_significance(av_areas, dispersion_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d87ea-409f-4c52-a549-70577670f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_pop = create_normalized_scatter_heat(np.mean(av_pop,0), label_arr, disp_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3120a-10b0-4b04-86af-e7b3d69e17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_layers = create_normalized_scatter_heat(np.mean(av_layers,0), label_arr_layers, disp_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4fed37-7e46-4902-918f-b1e89dc49084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_areas = create_normalized_scatter_heat(np.mean(av_areas,0), label_arr_areas, disp_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26895ab7-3e48-408c-b387-f91192c1cbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281388c-7603-41ee-96c6-5e3b923cc8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de3930-9f9d-4753-8706-850400ec2b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009608f-7e9d-4439-9f69-976ca0bd2920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
